{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff5c181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model components...\n",
      "‚úÖ Model loaded from stunting_decision_tree_model.pkl\n",
      "‚úÖ Scaler loaded from stunting_scaler.pkl\n",
      "‚úÖ Feature selector loaded from stunting_feature_selector.pkl\n",
      "‚úÖ Metadata loaded from stunting_decision_tree_metadata.json\n",
      "‚úÖ Feature names loaded: ['Umur (bulan)', 'Jenis Kelamin Encoded', 'Age_Groups', 'Height_Gender_Interaction', 'Height_Age_Ratio']\n",
      "Testing dengan sampel contoh...\n",
      "==================================================\n",
      "TESTING DENGAN SAMPEL BARU\n",
      "==================================================\n",
      "\n",
      "SAMPEL 1:\n",
      "Data input: {'Umur (bulan)': 24, 'Jenis Kelamin Encoded': 0, 'Age_Groups': 1, 'Height_Gender_Interaction': 85.0, 'Height_Age_Ratio': 3.5}\n",
      "Prediksi: Normal\n",
      "Confidence: 1.000\n",
      "Probabilitas Normal: 1.000\n",
      "Probabilitas Stunting: 0.000\n",
      "‚úÖ NORMAL - Pertahankan pola pertumbuhan\n",
      "\n",
      "SAMPEL 2:\n",
      "Data input: {'Umur (bulan)': 36, 'Jenis Kelamin Encoded': 1, 'Age_Groups': 2, 'Height_Gender_Interaction': 95.0, 'Height_Age_Ratio': 2.6}\n",
      "Prediksi: Normal\n",
      "Confidence: 0.970\n",
      "Probabilitas Normal: 0.970\n",
      "Probabilitas Stunting: 0.030\n",
      "‚úÖ NORMAL - Pertahankan pola pertumbuhan\n",
      "\n",
      "SAMPEL 3:\n",
      "Data input: {'Umur (bulan)': 12, 'Jenis Kelamin Encoded': 0, 'Age_Groups': 0, 'Height_Gender_Interaction': 70.0, 'Height_Age_Ratio': 5.8}\n",
      "Prediksi: Normal\n",
      "Confidence: 1.000\n",
      "Probabilitas Normal: 1.000\n",
      "Probabilitas Stunting: 0.000\n",
      "‚úÖ NORMAL - Pertahankan pola pertumbuhan\n",
      "\n",
      "üí° Untuk evaluasi lengkap, siapkan data test dan uncomment kode di atas\n",
      "\n",
      "‚úÖ Testing selesai!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score, \n",
    "                           precision_score, recall_score, f1_score, roc_auc_score)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class StuntingModelTester:\n",
    "    \"\"\"\n",
    "    Kelas untuk menguji model Decision Tree prediksi stunting\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path='stunting_decision_tree_model.pkl',\n",
    "                 scaler_path='stunting_scaler.pkl',\n",
    "                 selector_path='stunting_feature_selector.pkl',\n",
    "                 metadata_path='stunting_decision_tree_metadata.json'):\n",
    "        \"\"\"\n",
    "        Inisialisasi tester dengan memuat model dan komponen preprocessing\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.scaler_path = scaler_path\n",
    "        self.selector_path = selector_path\n",
    "        self.metadata_path = metadata_path\n",
    "        \n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.selector = None\n",
    "        self.metadata = None\n",
    "        self.feature_names = None\n",
    "        \n",
    "        self._load_model_components()\n",
    "    \n",
    "    def _load_model_components(self):\n",
    "        \"\"\"\n",
    "        Memuat semua komponen model yang diperlukan\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"Loading model components...\")\n",
    "            \n",
    "            # Load model\n",
    "            self.model = joblib.load(self.model_path)\n",
    "            print(f\"‚úÖ Model loaded from {self.model_path}\")\n",
    "            \n",
    "            # Load scaler\n",
    "            self.scaler = joblib.load(self.scaler_path)\n",
    "            print(f\"‚úÖ Scaler loaded from {self.scaler_path}\")\n",
    "            \n",
    "            # Load feature selector\n",
    "            self.selector = joblib.load(self.selector_path)\n",
    "            print(f\"‚úÖ Feature selector loaded from {self.selector_path}\")\n",
    "            \n",
    "            # Load metadata\n",
    "            with open(self.metadata_path, 'r') as f:\n",
    "                self.metadata = json.load(f)\n",
    "            print(f\"‚úÖ Metadata loaded from {self.metadata_path}\")\n",
    "            \n",
    "            # Get feature names\n",
    "            self.feature_names = self.metadata['features_used']\n",
    "            print(f\"‚úÖ Feature names loaded: {self.feature_names}\")\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"‚ùå Error: File not found - {e}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading model components: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def preprocess_data(self, X):\n",
    "        \"\"\"\n",
    "        Preprocessing data untuk testing (scaling dan feature selection)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Scale features\n",
    "            X_scaled = self.scaler.transform(X)\n",
    "            \n",
    "            # Select features\n",
    "            X_selected = self.selector.transform(X_scaled)\n",
    "            \n",
    "            return X_selected\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in preprocessing: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def predict_single(self, data_dict):\n",
    "        \"\"\"\n",
    "        Prediksi untuk satu sampel data\n",
    "        \n",
    "        Args:\n",
    "            data_dict: Dictionary berisi data sampel\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary berisi hasil prediksi dan probabilitas\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame([data_dict])\n",
    "            \n",
    "            # Ensure all required features are present\n",
    "            for feature in self.feature_names:\n",
    "                if feature not in df.columns:\n",
    "                    print(f\"‚ö†Ô∏è  Warning: Feature '{feature}' not found, setting to 0\")\n",
    "                    df[feature] = 0\n",
    "            \n",
    "            # Select only required features\n",
    "            X = df[self.feature_names]\n",
    "            \n",
    "            # Preprocess\n",
    "            X_processed = self.preprocess_data(X)\n",
    "            \n",
    "            # Predict\n",
    "            prediction = self.model.predict(X_processed)[0]\n",
    "            probabilities = self.model.predict_proba(X_processed)[0]\n",
    "            \n",
    "            result = {\n",
    "                'prediction': int(prediction),\n",
    "                'prediction_label': 'Stunting' if prediction == 1 else 'Normal',\n",
    "                'probability_normal': float(probabilities[0]),\n",
    "                'probability_stunting': float(probabilities[1]),\n",
    "                'confidence': float(max(probabilities)),\n",
    "                'input_data': data_dict\n",
    "            }\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in single prediction: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def predict_batch(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Prediksi untuk batch data\n",
    "        \n",
    "        Args:\n",
    "            X: DataFrame berisi fitur\n",
    "            y: Array berisi label sebenarnya (optional)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary berisi prediksi dan evaluasi (jika y tersedia)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Ensure all required features are present\n",
    "            missing_features = []\n",
    "            for feature in self.feature_names:\n",
    "                if feature not in X.columns:\n",
    "                    missing_features.append(feature)\n",
    "                    X[feature] = 0\n",
    "            \n",
    "            if missing_features:\n",
    "                print(f\"‚ö†Ô∏è  Warning: Missing features set to 0: {missing_features}\")\n",
    "            \n",
    "            # Select only required features\n",
    "            X_selected = X[self.feature_names]\n",
    "            \n",
    "            # Preprocess\n",
    "            X_processed = self.preprocess_data(X_selected)\n",
    "            \n",
    "            # Predict\n",
    "            predictions = self.model.predict(X_processed)\n",
    "            probabilities = self.model.predict_proba(X_processed)\n",
    "            \n",
    "            result = {\n",
    "                'predictions': predictions,\n",
    "                'probabilities': probabilities,\n",
    "                'predictions_labels': ['Stunting' if p == 1 else 'Normal' for p in predictions]\n",
    "            }\n",
    "            \n",
    "            # Evaluate if true labels provided\n",
    "            if y is not None:\n",
    "                evaluation = self.evaluate_predictions(y, predictions, probabilities[:, 1])\n",
    "                result['evaluation'] = evaluation\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in batch prediction: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def evaluate_predictions(self, y_true, y_pred, y_proba):\n",
    "        \"\"\"\n",
    "        Evaluasi performa prediksi\n",
    "        \"\"\"\n",
    "        try:\n",
    "            evaluation = {\n",
    "                'accuracy': accuracy_score(y_true, y_pred),\n",
    "                'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "                'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "                'f1_score': f1_score(y_true, y_pred, zero_division=0),\n",
    "                'confusion_matrix': confusion_matrix(y_true, y_pred).tolist(),\n",
    "                'classification_report': classification_report(y_true, y_pred, \n",
    "                                                              target_names=['Normal', 'Stunting'],\n",
    "                                                              output_dict=True)\n",
    "            }\n",
    "            \n",
    "            # ROC AUC if possible\n",
    "            try:\n",
    "                evaluation['roc_auc'] = roc_auc_score(y_true, y_proba)\n",
    "            except:\n",
    "                evaluation['roc_auc'] = None\n",
    "            \n",
    "            return evaluation\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in evaluation: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_test_report(self, X_test, y_test, save_report=True):\n",
    "        \"\"\"\n",
    "        Generate comprehensive test report\n",
    "        \"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"LAPORAN PENGUJIAN MODEL STUNTING DECISION TREE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Model info\n",
    "        print(f\"\\nINFORMASI MODEL:\")\n",
    "        print(f\"- Tipe Model: {self.metadata['model_type']}\")\n",
    "        print(f\"- Tanggal Training: {self.metadata['training_date']}\")\n",
    "        print(f\"- Jumlah Fitur: {len(self.feature_names)}\")\n",
    "        print(f\"- Fitur yang Digunakan: {', '.join(self.feature_names)}\")\n",
    "        \n",
    "        # Model parameters\n",
    "        print(f\"\\nPARAMETER MODEL:\")\n",
    "        for key, value in self.metadata['parameters'].items():\n",
    "            print(f\"- {key}: {value}\")\n",
    "        \n",
    "        # Predict on test data\n",
    "        print(f\"\\nTESTING PADA DATA UJI...\")\n",
    "        print(f\"Jumlah sampel test: {len(X_test)}\")\n",
    "        \n",
    "        result = self.predict_batch(X_test, y_test)\n",
    "        \n",
    "        if result and 'evaluation' in result:\n",
    "            eval_data = result['evaluation']\n",
    "            \n",
    "            print(f\"\\nHASIL EVALUASI:\")\n",
    "            print(f\"- Accuracy: {eval_data['accuracy']:.3f}\")\n",
    "            print(f\"- Precision: {eval_data['precision']:.3f}\")\n",
    "            print(f\"- Recall: {eval_data['recall']:.3f}\")\n",
    "            print(f\"- F1-Score: {eval_data['f1_score']:.3f}\")\n",
    "            if eval_data['roc_auc']:\n",
    "                print(f\"- ROC AUC: {eval_data['roc_auc']:.3f}\")\n",
    "            \n",
    "            # Confusion Matrix\n",
    "            cm = np.array(eval_data['confusion_matrix'])\n",
    "            print(f\"\\nCONFUSION MATRIX:\")\n",
    "            print(\"             Predicted\")\n",
    "            print(\"Actual    Normal  Stunting\")\n",
    "            print(f\"Normal      {cm[0,0]:6d}  {cm[0,1]:8d}\")\n",
    "            print(f\"Stunting    {cm[1,0]:6d}  {cm[1,1]:8d}\")\n",
    "            \n",
    "            # Performance comparison with training\n",
    "            print(f\"\\nPERBANDINGAN DENGAN PERFORMA TRAINING:\")\n",
    "            train_f1 = self.metadata['performance']['cv_f1_mean']\n",
    "            test_f1 = eval_data['f1_score']\n",
    "            \n",
    "            print(f\"- Training F1 (CV): {train_f1:.3f}\")\n",
    "            print(f\"- Testing F1: {test_f1:.3f}\")\n",
    "            print(f\"- Selisih: {abs(train_f1 - test_f1):.3f}\")\n",
    "            \n",
    "            if abs(train_f1 - test_f1) > 0.1:\n",
    "                print(\"‚ö†Ô∏è  Warning: Perbedaan performa signifikan, kemungkinan overfitting!\")\n",
    "            else:\n",
    "                print(\"‚úÖ Performa konsisten antara training dan testing\")\n",
    "            \n",
    "            # Save report if requested\n",
    "            if save_report:\n",
    "                report_data = {\n",
    "                    'test_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'model_info': self.metadata,\n",
    "                    'test_results': eval_data,\n",
    "                    'test_data_size': len(X_test),\n",
    "                    'performance_comparison': {\n",
    "                        'training_f1': train_f1,\n",
    "                        'testing_f1': test_f1,\n",
    "                        'difference': abs(train_f1 - test_f1)\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                with open('stunting_test_report.json', 'w') as f:\n",
    "                    json.dump(report_data, f, indent=2)\n",
    "                print(f\"\\nüìÑ Laporan tersimpan: stunting_test_report.json\")\n",
    "            \n",
    "            # Visualization\n",
    "            self._plot_test_results(eval_data, cm)\n",
    "            \n",
    "            return result\n",
    "        else:\n",
    "            print(\"‚ùå Gagal melakukan evaluasi\")\n",
    "            return None\n",
    "    \n",
    "    def _plot_test_results(self, eval_data, cm):\n",
    "        \"\"\"\n",
    "        Plot test results\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['Normal', 'Stunting'],\n",
    "                   yticklabels=['Normal', 'Stunting'], ax=axes[0,0])\n",
    "        axes[0,0].set_title('Confusion Matrix')\n",
    "        axes[0,0].set_xlabel('Predicted')\n",
    "        axes[0,0].set_ylabel('Actual')\n",
    "        \n",
    "        # Performance Metrics\n",
    "        metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "        values = [eval_data['accuracy'], eval_data['precision'], \n",
    "                 eval_data['recall'], eval_data['f1_score']]\n",
    "        \n",
    "        bars = axes[0,1].bar(metrics, values, color=['skyblue', 'lightgreen', 'lightcoral', 'gold'])\n",
    "        axes[0,1].set_title('Performance Metrics')\n",
    "        axes[0,1].set_ylabel('Score')\n",
    "        axes[0,1].set_ylim(0, 1)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, values):\n",
    "            axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                          f'{value:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Performance comparison\n",
    "        train_metrics = ['Training F1', 'Testing F1']\n",
    "        train_f1 = self.metadata['performance']['cv_f1_mean']\n",
    "        test_f1 = eval_data['f1_score']\n",
    "        comparison_values = [train_f1, test_f1]\n",
    "        \n",
    "        bars = axes[1,0].bar(train_metrics, comparison_values, \n",
    "                            color=['lightblue', 'orange'])\n",
    "        axes[1,0].set_title('Training vs Testing F1-Score')\n",
    "        axes[1,0].set_ylabel('F1-Score')\n",
    "        axes[1,0].set_ylim(0, 1)\n",
    "        \n",
    "        for bar, value in zip(bars, comparison_values):\n",
    "            axes[1,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                          f'{value:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Feature importance (from metadata)\n",
    "        if 'feature_importance' in self.metadata:\n",
    "            features = list(self.metadata['feature_importance'].keys())\n",
    "            importance = list(self.metadata['feature_importance'].values())\n",
    "            \n",
    "            axes[1,1].barh(features, importance)\n",
    "            axes[1,1].set_title('Feature Importance')\n",
    "            axes[1,1].set_xlabel('Importance')\n",
    "        else:\n",
    "            axes[1,1].text(0.5, 0.5, 'Feature Importance\\nNot Available', \n",
    "                          ha='center', va='center', transform=axes[1,1].transAxes)\n",
    "            axes[1,1].set_title('Feature Importance')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('stunting_test_results_visualization.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"üìä Visualisasi tersimpan: stunting_test_results_visualization.png\")\n",
    "        plt.show()\n",
    "    \n",
    "    def test_new_samples(self, samples_data):\n",
    "        \"\"\"\n",
    "        Test dengan data sampel baru\n",
    "        \n",
    "        Args:\n",
    "            samples_data: List of dictionaries berisi data sampel\n",
    "        \"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(\"TESTING DENGAN SAMPEL BARU\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        for i, sample in enumerate(samples_data, 1):\n",
    "            print(f\"\\nSAMPEL {i}:\")\n",
    "            print(f\"Data input: {sample}\")\n",
    "            \n",
    "            result = self.predict_single(sample)\n",
    "            \n",
    "            if result:\n",
    "                print(f\"Prediksi: {result['prediction_label']}\")\n",
    "                print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "                print(f\"Probabilitas Normal: {result['probability_normal']:.3f}\")\n",
    "                print(f\"Probabilitas Stunting: {result['probability_stunting']:.3f}\")\n",
    "                \n",
    "                # Interpretasi\n",
    "                if result['prediction'] == 1:\n",
    "                    if result['confidence'] > 0.8:\n",
    "                        print(\"üî¥ RISIKO TINGGI - Perlu perhatian medis segera\")\n",
    "                    elif result['confidence'] > 0.6:\n",
    "                        print(\"üü° RISIKO SEDANG - Monitoring dan intervensi diperlukan\")\n",
    "                    else:\n",
    "                        print(\"üü¢ RISIKO RENDAH - Tetap monitor perkembangan\")\n",
    "                else:\n",
    "                    print(\"‚úÖ NORMAL - Pertahankan pola pertumbuhan\")\n",
    "            else:\n",
    "                print(\"‚ùå Gagal melakukan prediksi\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "# Fungsi utility untuk membuat data test\n",
    "def create_sample_test_data():\n",
    "    \"\"\"\n",
    "    Membuat data sampel untuk testing\n",
    "    \"\"\"\n",
    "    samples = [\n",
    "        {\n",
    "            'Umur (bulan)': 24,\n",
    "            'Jenis Kelamin Encoded': 0,  # Laki-laki\n",
    "            'Age_Groups': 1,\n",
    "            'Height_Gender_Interaction': 85.0,\n",
    "            'Height_Age_Ratio': 3.5\n",
    "        },\n",
    "        {\n",
    "            'Umur (bulan)': 36,\n",
    "            'Jenis Kelamin Encoded': 1,  # Perempuan\n",
    "            'Age_Groups': 2,\n",
    "            'Height_Gender_Interaction': 95.0,\n",
    "            'Height_Age_Ratio': 2.6\n",
    "        },\n",
    "        {\n",
    "            'Umur (bulan)': 12,\n",
    "            'Jenis Kelamin Encoded': 0,  # Laki-laki\n",
    "            'Age_Groups': 0,\n",
    "            'Height_Gender_Interaction': 70.0,\n",
    "            'Height_Age_Ratio': 5.8\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# Fungsi utama untuk testing\n",
    "def run_model_testing():\n",
    "    \"\"\"\n",
    "    Fungsi utama untuk menjalankan testing model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize tester\n",
    "        tester = StuntingModelTester()\n",
    "        \n",
    "        # Test dengan sampel baru\n",
    "        print(\"Testing dengan sampel contoh...\")\n",
    "        sample_data = create_sample_test_data()\n",
    "        tester.test_new_samples(sample_data)\n",
    "        \n",
    "        # Jika ada data test tersedia, lakukan evaluasi lengkap\n",
    "        try:\n",
    "            # Coba load data test (sesuaikan dengan format data Anda)\n",
    "            # test_data = pd.read_csv('test_data.csv')  # Ganti dengan path file test\n",
    "            # X_test = test_data[tester.feature_names]\n",
    "            # y_test = test_data['Is_Stunting']\n",
    "            # tester.generate_test_report(X_test, y_test)\n",
    "            print(\"\\nüí° Untuk evaluasi lengkap, siapkan data test dan uncomment kode di atas\")\n",
    "            \n",
    "        except:\n",
    "            print(\"\\nüí° Data test tidak tersedia untuk evaluasi lengkap\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Testing selesai!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error dalam testing: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_model_testing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
